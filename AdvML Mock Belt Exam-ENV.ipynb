{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc8790ae-0026-4c1c-9118-79929d97fdca",
   "metadata": {},
   "source": [
    "# <center><u>AdvML Mock Belt Exam\n",
    "- Authored by: Eric N. Valdez\n",
    "- Data: 04/10/2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e1ee56-b01e-49b8-a92a-f1ffe7d54fcf",
   "metadata": {},
   "source": [
    "# `Part 1: NLP`\n",
    "## Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73f95ce-15cf-4821-8822-8f552b6cdce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "## Import Modeling Package\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Set Random Seeds\n",
    "tf.keras.utils.set_random_seed(42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ce07ef-f30c-4b48-bba8-d92125334cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase column width\n",
    "pd.set_option('display.max_colwidth', 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd41051-3d5c-400e-a12a-5ba9ddeacb64",
   "metadata": {},
   "source": [
    "## Preprocessing:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d428549-146d-42b7-80a6-8e763bd568c4",
   "metadata": {},
   "source": [
    "### <u>Load functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101b8cb-0bfd-4f9c-9e4e-92713b67e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import exam_functions as fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223055b7-a26e-4aac-a2e3-abcb8f2eb791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/part1-aml-belt-exam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa2b5c1-f2a2-41a9-80ce-adca8c58f1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading NLP Lite\n",
    "nlp_lite = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "nlp_lite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03658692-52f9-4adc-a547-79b911f11714",
   "metadata": {},
   "source": [
    "## <u>Preprocess with spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a7453f-d3a4-4e6a-8081-d659b4f744f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokens\n",
    "%%time\n",
    "\n",
    "df['tokens']= fn.batch_preprocess_texts(df['paragraph'],nlp=nlp_lite, remove_stopwords \\\n",
    "                                        = True, remove_punct =True, use_lemmas = False,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21185746-1474-412a-9b75-e7a708e91796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemamatized\n",
    "%%time\n",
    "df['lemmas']= fn.batch_preprocess_texts(df['paragraph'],nlp=nlp_lite, remove_stopwords \\\n",
    "                                        = True, remove_punct =True, use_lemmas = True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32cc53aa-c0d2-4325-9d47-7aa22fdf411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee51970-316d-4b22-ad12-354d6814b313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joined tokens\n",
    "df['joined_tokens'] = df['tokens'].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0a7c41-130d-4232-9ff8-1600f42e6ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joined_tokens']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca2242d-e877-4efa-bb84-5e23f2df4d3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joined lemmas\n",
    "df['joined_lemmas'] = df['lemmas'].map(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8138db-ecbd-4ab6-992a-a96d3f6a62a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['joined_lemmas']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76816c51-2c00-4984-9a7c-e4cf41a6ab16",
   "metadata": {},
   "source": [
    "## Perform group comparison EDA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15be2781-8acf-4743-a748-f8717a22e3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate 2 groups based on source\n",
    "df['source'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7db9d7a-3e81-4f7e-b156-63c97b661bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_ConanDoyle = df.loc[df['source'] == 'Conan Doyle']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d923bde-47e9-421b-95b0-f7867ef152e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_ConanDoyle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e091420e-164c-4c1a-90dc-5831b3d32882",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_Christie = df.loc[df['source'] == 'Christie']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221a2e38-4d54-491b-83a5-bb3616ba4a91",
   "metadata": {},
   "source": [
    "## <u>Word Clouds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be7fa6-03d7-4390-9892-29fb0bffe208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text for group CananDoyle and display\n",
    "\n",
    "grp_ConanDoyle_text = \" \".join(grp_ConanDoyle['paragraph'])\n",
    "print(grp_ConanDoyle_text[:500],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6744559a-3b40-4911-a46e-39f9d2464276",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text for group Christie and display\n",
    "\n",
    "grp_Christie_text = \" \".join(grp_Christie['paragraph'])\n",
    "print(grp_Christie_text[:500],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c9209-00af-4556-a9c7-1f53cef304ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word clouds of above texts\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "ConanDoyle_cloud = WordCloud(min_word_length=2).generate(grp_ConanDoyle_text)\n",
    "Christie_cloud = WordCloud(min_word_length=2).generate(grp_Christie_text)\n",
    "\n",
    "## Plot the Images\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "axes[0].imshow(ConanDoyle_cloud)\n",
    "axes[0].set_title('ConanDoyle words')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(Christie_cloud)\n",
    "axes[1].set_title('Christie Words')\n",
    "axes[1].axis('off');\n",
    "fig.suptitle('Word Cloud - Raw text');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eadac81-142f-445d-a10f-acfdd29cd2b3",
   "metadata": {},
   "source": [
    "## <u> Word Clouds using Lemmatized Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fa2e70-8607-4ccd-bf2d-f250e9f26acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the text for group CananDoyle and display\n",
    "\n",
    "grp_ConanDoyle_text = \" \".join(grp_ConanDoyle['joined_lemmas'])\n",
    "print(grp_ConanDoyle_text[:500],\"\\n\")\n",
    "\n",
    "# get the text for group Christie and display\n",
    "\n",
    "grp_Christie_text = \" \".join(grp_Christie['joined_lemmas'])\n",
    "print(grp_Christie_text[:500],\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8eceff-ff59-4f2d-887c-62725e3a3299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word clouds of above texts\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "ConanDoyle_cloud = WordCloud(min_word_length=2).generate(grp_ConanDoyle_text)\n",
    "Christie_cloud = WordCloud(min_word_length=2).generate(grp_Christie_text)\n",
    "\n",
    "## Plot the Images\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2, figsize=(12, 6))\n",
    "axes[0].imshow(ConanDoyle_cloud)\n",
    "axes[0].set_title('ConanDoyle words')\n",
    "axes[0].axis('off')\n",
    "\n",
    "axes[1].imshow(Christie_cloud)\n",
    "axes[1].set_title('Christie Words')\n",
    "axes[1].axis('off')\n",
    "fig.suptitle('Word Cloud - Lemmas');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee4e25b-b78c-40ba-82c4-d552f7c194ab",
   "metadata": {},
   "source": [
    "## <u> Top 20 most frequent bigrams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dd7d54-11d1-4f5b-9c9c-f6b2afd9c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_ConanDoyle_tokens = grp_ConanDoyle['tokens'].explode().astype(str).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc63738d-5480-41ff-b8a5-c37788f7e04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_Christie_tokens = grp_Christie['tokens'].explode().astype(str).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4919181-95fd-413c-b3b2-1164dbf10611",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_ConanDoyle_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a0f0d5f-4d75-4941-833a-d114596505da",
   "metadata": {},
   "outputs": [],
   "source": [
    "grp_Christie_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a162b-b418-4212-a446-1a26ee0081ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using custom function get_ngram_measures_finder to get the bigrams\n",
    "\n",
    "bigram_grp_ConanDoyle = fn.get_ngram_measures_finder(grp_ConanDoyle_tokens,top_n=20)\n",
    "\n",
    "bigram_grp_Christie = fn.get_ngram_measures_finder(grp_Christie_tokens,top_n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b74ea3d-3edb-428c-9e5c-5ccffff74416",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_grp_ConanDoyle,bigram_grp_Christie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e200d603-9bfe-47cb-b7f3-a75684f39e3e",
   "metadata": {},
   "source": [
    "## <u>Text Classification - Machine Learning\n",
    "- ### Build, fit, and evaluate a binary MultinomialNB classifier to predict the author (source) from the original raw paragraphs text.\n",
    "    -  Do not remove stopwords\n",
    "    -  \n",
    "No need to balance the datase\n",
    "    -  \r\n",
    "Use a pipeline to include the count vectorizer and classification mod\n",
    "    -  l\r\n",
    "You do not need to tune the mo\n",
    "    -  el\r\n",
    "Save your model pipeline to a Models folder in your repo as a joblib file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d64ff9-0750-4804-9498-638c1406a00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67bcd43-0924-4b95-818a-84c509c8b6ae",
   "metadata": {},
   "source": [
    "`Defining X and y`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27e571-6049-4937-a38a-eaf5e38a71e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define X and y\n",
    "\n",
    "X = df['paragraph']\n",
    "y = df['source']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051cc30e-bf1c-453d-b0ae-cfa329c431c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Value Counts for y\n",
    "\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6dfaf05-45ec-4d54-b053-7f0a81eef02c",
   "metadata": {},
   "source": [
    "`Train Test Split`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23de2e0b-1b61-4de2-a9bb-72d385533886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3331f7d3-baf5-48c7-8801-c0298adda697",
   "metadata": {},
   "source": [
    "`Modeling using MultinomialNB Classifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8330ed4c-0bfe-4934-ab95-5e94f44daedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling using raw text (paragraph) , creating pipeline with count vectorizer and classification model\n",
    "\n",
    "## Create a model pipeline for inference.\n",
    "nb_clf = MultinomialNB()\n",
    "\n",
    "nb_pipe = Pipeline([('countvectorizer', CountVectorizer()), \n",
    "                       ('nb_classifier', nb_clf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18e3d3c-e1b2-4ebf-9aa4-9553b4f08e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f840cbdb-a6b5-48f7-a920-ff3559860a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using custom classification evaluation function to evaluate\n",
    "fn.evaluate_classification(nb_pipe, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f983a-7a5e-4ce9-a042-d90507ebe325",
   "metadata": {},
   "source": [
    "## `Saving model pipeline to a Models folder in repo as a joblib file.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f3e472-e2b0-4f70-913f-47570b1787b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.makedirs('Models/' ,exist_ok =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0588eb-3d5a-43c4-93dd-24f5096a3a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "fpath_model = \"Models/nb_classifierexam.joblib\"\n",
    "joblib.dump(nb_pipe, fpath_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab4a7c7-75f8-443c-a7c9-55ca8b7ce2e7",
   "metadata": {},
   "source": [
    "# <u>Text Classification - Deep NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da0e761-f74b-45a6-9b51-971abeb923d1",
   "metadata": {},
   "source": [
    "### `Prepare tensorflow datasets for a train/val/test split`\n",
    "- No need to balance classes\n",
    "- `Note:` Make sure your target is encoded numerically (integers).\n",
    "- Use a batch size of 32.\n",
    "- Select a sequence length appropriate for the dataset's text.\n",
    "    - Add a column to the dataframe that has the length of each paragraph\n",
    "    - Use the maximum length as the sequence length\n",
    "        - `Note:` if your computer is having memory/PC issues when fitting the model, reduce the sequence length and add a comment listing the maximum length and why you had to reduce it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb9bfdd-790f-4e09-a112-8d050ce1d94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use labelencoder to encode the target \n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47041aa-69d3-4dc2-b438-971e066e052c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a batch size of 32\n",
    "BATCH_SIZE =32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee56098-86a3-4254-a880-556b0bf18edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['paragraph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3ae83b-9c7c-462f-812e-5c70023ed422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the length of the each text, and spliting on each space, and then get the length\n",
    "df['sequence_length'] =df['paragraph'].map( lambda x: len(x.split(\" \")))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24e2be0-c334-4baf-8bbb-bbb789748724",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sequence_length'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46531c70-afa5-4e3b-ad2e-a103bb8712fd",
   "metadata": {},
   "source": [
    "- ### `The range of sequence length is from 4 to 33`\n",
    "\n",
    "- ### `Lets take maximum sequence length as 40`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6158692b-91f0-4294-b20c-b59a53fa29ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fa46cd-2f4c-45d8-b609-dccb4b6550ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40\n",
    "# Make histogram of sequence lengths\n",
    "ax = df['sequence_length'].hist(bins = 'auto')\n",
    "ax.set_xlabel('Paragraph')\n",
    "ax.set_ylabel('count')\n",
    "ax.set_title('Distribution of Sequence Lengths');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e280a48-2ea3-4225-bbfe-eca0bb77b815",
   "metadata": {},
   "source": [
    "## `Build, fit, and evaluate a binary classification sequence model`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e79fb3-26f7-4be1-a81a-8caa7d3f9087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset for modeling\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbe9676-278c-4bff-bbd1-c22146566572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the dataset for modeling\n",
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5755a75-ba55-45f8-9aa0-9f952af76725",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = np.unique(y_encoded)\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c981017-ccfb-451e-aa67-fbb9dc04c798",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting to a dataset object using Dataset.from_tensor_slices()\n",
    "ds = tf.data.Dataset.from_tensor_slices((X, y_encoded))\n",
    "\n",
    "# Shuffle dataset\n",
    "ds = ds.shuffle(buffer_size=len(ds),reshuffle_each_iteration=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd1ad8b-6db0-45b5-889e-4c82b23ceb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train, test, split with a .7, .2, .1 ratio using the take, skip, approach\n",
    "\n",
    "# Set the ratio of the train, validation, test split\n",
    "split_train = .7\n",
    "split_val =  .2\n",
    "split_test =  1 -( split_train + split_val )\n",
    "\n",
    "# Calculate the number of samples for training and validation data \n",
    "n_train_samples =  int(len(ds) * split_train)\n",
    "n_val_samples = int(len(ds) * split_val)\n",
    "n_test_samples = len(ds) -(n_train_samples + n_val_samples)\n",
    "\n",
    "import math\n",
    "# math.ceil will round up\n",
    "# How many batches? \n",
    "n_train_batches = math.ceil(n_train_samples/BATCH_SIZE)\n",
    "n_val_batches = math.ceil(n_val_samples/BATCH_SIZE)\n",
    "n_test_batches = math.ceil(n_test_samples/BATCH_SIZE)\n",
    "\n",
    "print(f\"    - train:\\t{n_train_samples} samples \\t({n_train_batches} batches)\")\n",
    "print(f\"    - val:  \\t{n_val_samples} samples \\t({n_val_batches} batches)\")\n",
    "print(f\"    - test: \\t{n_test_samples} samples \\t({n_test_batches} batches)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14958ec4-b91d-4970-a26e-dfe70a2eb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use take and skip to define each set\n",
    "train_ds = ds.take(n_train_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skip over the training batches and take the validation batches\n",
    "val_ds = ds.skip(n_train_samples).take(n_val_samples).batch(batch_size=BATCH_SIZE)\n",
    "\n",
    "# Skipver the train and validation batches, the remaining are the test batches\n",
    "test_ds = ds.skip(n_train_samples + n_val_samples).batch(batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee891edb-d164-408c-af43-4ab2331d78dd",
   "metadata": {},
   "source": [
    "`Include a Keras TextVectorization as a layer in your model.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b61ff-f247-41f1-b1f7-87a2f8890726",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQUENCE_LENGTH = 40\n",
    "# Create text Vectorization layer\n",
    "text_vectorizer = tf.keras.layers.TextVectorization(\n",
    "    standardize=\"lower_and_strip_punctuation\",\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=SEQUENCE_LENGTH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297fe6bd-fc8c-4a35-bf23-9189c55a2e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get just the text from ds_train\n",
    "ds_texts = train_ds.map(lambda x, y_encoded: x)\n",
    "\n",
    "# Preview the text\n",
    "ds_texts.take(1).get_single_element()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed888d4-ef48-4880-b6af-c8a1e7bcc075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (adapt on training text data))\n",
    "text_vectorizer.adapt(ds_texts)\n",
    "text_vectorizer.vocabulary_size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6e903f-7096-48fd-8b75-6f9db534ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Programmatically define size of vocab from vectorization layer\n",
    "VOCAB_SIZE = text_vectorizer.vocabulary_size()\n",
    "VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77879572-6ade-41ab-b4ba-fe4ff0bc48fa",
   "metadata": {},
   "source": [
    "`Use 100 as the embedding dimension/size`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc59dcd-1d44-494e-a528-6e27a1a04fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBED_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b3ce2e-94fd-4c7f-beb3-d1c472275aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'VOCAB_SIZE is {VOCAB_SIZE}')\n",
    "print(f'SEQUENCE_LENGTH is {SEQUENCE_LENGTH}')\n",
    "print(f'EMBED_DIM is {EMBED_DIM}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f24e85-46b9-4ef2-ac5a-940237a1e2f0",
   "metadata": {},
   "source": [
    "`Use a bidirectional GRU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9876c61a-9f60-4c14-aac8-160cc4bd8c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using custom functions\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "def build_gru_model(text_vectorization_layer):\n",
    "                \n",
    "    gru_model = Sequential([\n",
    "        text_vectorization_layer,\n",
    "        tf.keras.layers.Embedding(input_dim=VOCAB_SIZE, \n",
    "                                  output_dim=EMBED_DIM, \n",
    "                                  input_length=SEQUENCE_LENGTH)])\n",
    "    # Add GRU layer *new*\n",
    "    gru_model.add(layers.GRU(128, return_sequences = True))   \n",
    "    gru_model.add(layers.GlobalMaxPooling1D())\n",
    "    # Output layer\n",
    "    gru_model.add(layers.Dense(len(classes), \n",
    "                              activation='softmax'))\n",
    "        \n",
    "    optimizer = optimizers.legacy.Adam()\n",
    "    gru_model.compile(optimizer=optimizer,  \n",
    "                  loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    gru_model.summary()\n",
    "    return gru_model\n",
    "\n",
    "\n",
    "# Include callbacks\n",
    "def get_callbacks(patience=3, monitor='val_accuracy'):\n",
    "    early_stop = tf.keras.callbacks.EarlyStopping(patience=patience, monitor=monitor)\n",
    "    return [early_stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147f1649-d274-4019-88c0-4b43802972bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the gru model and specify the vectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, optimizers, regularizers\n",
    "\n",
    "gru_model = build_gru_model(text_vectorizer)\n",
    "\n",
    "# Defien number of epocs\n",
    "EPOCHS = 30\n",
    "\n",
    "# Fit the model\n",
    "history = gru_model.fit(\n",
    "    train_ds,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=get_callbacks(),\n",
    ")\n",
    "\n",
    "# Obtain the results\n",
    "results = fn.evaluate_classification_network(\n",
    "    gru_model, X_train=train_ds, \n",
    "    X_test=test_ds, history=history\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d20a64-d526-4c42-bd40-397adf81f425",
   "metadata": {},
   "source": [
    "### `Save your model to a Models folder in your repo in the SavedModel format (save_format='tf').`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c512567-bcd4-474f-9002-195d23f8bea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpath_model = \"Models/gru\"\n",
    "#tf.keras.models.save_model(model, fpath_model)\n",
    "gru_model.save(fpath_model, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dccaba8-e33f-4fcd-bd8a-ad6f5bbebb76",
   "metadata": {},
   "source": [
    "# <u>Part 2 Deployment:\n",
    "- For this part of the exam, you will create a Streamlit app that will allow users to predict the price of a home by inputting certain information about it. It will include inputs for features of the home and produce a predicted price.\n",
    "- In a new notebook, load in the filepaths.json file from the config folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79d3634-b4bf-461a-82dd-fb92b208244e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fe6896-5b02-496f-b307-d106eb201b0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0134197e-afac-4729-a265-fdfafa1c7021",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227df176-b196-4240-bf83-e8a5bf2c3797",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ea73f-5e7c-4f55-bba9-667e0531c189",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c8eb11-adce-49e9-b281-53cfb05fd109",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148072a-9ab4-4dee-a7da-0ce784100c40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2770d-97df-464f-97b4-9c605e2045be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7a39d0-37bc-4b76-b927-fbcd45e0e469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c97ac-3d03-47a1-a534-aaa6d0a90a38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e472145-2c2a-4872-a61c-2abfcd88439b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d77de122-6d00-4c1f-a512-eaeff98ff6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14650516-ebd5-4259-b262-0df3969cbaa0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dojo-env)",
   "language": "python",
   "name": "dojo-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
